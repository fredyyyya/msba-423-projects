{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Traffic Signal"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set-up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load libraries\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.functions import col, when, udf, stddev\n",
    "from pyspark.sql.types import FloatType\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.feature import StringIndexer, OneHotEncoder, VectorAssembler\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/06/08 17:29:43 WARN Utils: Your hostname, Shaolongs-MacBook-Pro.local resolves to a loopback address: 127.0.0.1; using 192.168.4.167 instead (on interface en0)\n",
      "23/06/08 17:29:43 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "23/06/08 17:29:43 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "23/06/08 17:29:44 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "23/06/08 17:29:44 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.\n",
      "23/06/08 17:29:44 WARN Utils: Service 'SparkUI' could not bind on port 4042. Attempting port 4043.\n"
     ]
    }
   ],
   "source": [
    "# Start session\n",
    "spark = SparkSession\\\n",
    "        .builder\\\n",
    "        .config(\"spark.driver.memory\", \"4g\")\\\n",
    "        .config(\"spark.executor.memory\", \"4g\")\\\n",
    "        .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data\n",
    "path = \"/Users/shaolongxue/Documents/MSBA/3_Spring_Quarter/BAX423_Big_Data_Analytics/Final Project/Data/US_Traffic_v02.csv\"\n",
    "data = spark.read.format('csv').option('header', 'true').load(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/06/08 17:30:09 WARN package: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Select relevant features\n",
    "cols_to_remove = [\"Start_Lat\", \"Start_Lng\", \"End_Lat\", \"End_Lng\", \"Description\", \n",
    "                  \"Number\", \"Street\", \"Country\", \"Timezone\", \"Airport_Code\", \"Zipcode\", \n",
    "                  \"Weather_Timestamp\", \"Sunrise_Sunset\", \"Civil_Twilight\", \"Nautical_Twilight\", \n",
    "                  \"Astronomical_Twilight\", \"Weather_Condition\", \"Wind_Direction\"]\n",
    "\n",
    "df = data.select([col for col in data.columns if col not in cols_to_remove])\n",
    "\n",
    "df = df.na.drop()\n",
    "\n",
    "# Cast numeric columns to appropriate types\n",
    "double_columns = [\"Distance(mi)\", \"Temperature(F)\", \"Wind_Chill(F)\", \n",
    "                   \"Humidity(%)\", \"Pressure(in)\", \"Visibility(mi)\", \n",
    "                   \"Wind_Speed(mph)\", \"Precipitation(in)\", \"Duration\"]\n",
    "\n",
    "integer_columns = [\"Population\", \"Start_Year\", \"Start_Month\"]\n",
    "\n",
    "for column in double_columns:\n",
    "    df = df.withColumn(column, col(column).cast(\"double\"))\n",
    "\n",
    "for column in integer_columns:\n",
    "    df = df.withColumn(column, col(column).cast(\"integer\"))\n",
    "\n",
    "# Remove one outlier row wither Side is \"N\"\n",
    "df = df.where(df.Side != 'N')\n",
    "# Remove outliers where duration is larger than 7 days\n",
    "df = df.where(df.Duration <= 168)\n",
    "\n",
    "# Encode binary categorical columns\n",
    "binary_columns = ['Amenity', 'Bump', 'Crossing', 'Give_Way', 'Junction', 'No_Exit', 'Railway', 'Roundabout', 'Station', 'Stop', 'Traffic_Calming', 'Traffic_Signal', 'Turning_Loop']\n",
    "\n",
    "for column in binary_columns:\n",
    "    df = df.withColumn(column, when(col(column) == \"true\", 1).otherwise(0))\n",
    "\n",
    "df = df.withColumn(\"Side\", when(col(\"Side\") == \"L\", 1).otherwise(0))\n",
    "\n",
    "# Convert values in Start_TOD_Category column [Necessary for SMOTE]\n",
    "df = df.withColumn(\"Start_TOD_Category\",\n",
    "                    when(df[\"Start_TOD_Category\"] == \"Midnight\", \"1\")\n",
    "                   .when(df[\"Start_TOD_Category\"] == \"Early Morning\", \"2\")\n",
    "                   .when(df[\"Start_TOD_Category\"] == \"Late Morning\", \"3\")\n",
    "                   .when(df[\"Start_TOD_Category\"] == \"Early Afternoon\", \"4\")\n",
    "                   .when(df[\"Start_TOD_Category\"] == \"Late Afternoon\", \"5\")\n",
    "                   .when(df[\"Start_TOD_Category\"] == \"Evening\", \"6\"))\n",
    "\n",
    "# First convert the categories from 'string' to 'index'\n",
    "indexer = StringIndexer(inputCol=\"Start_TOD_Category\", outputCol=\"Start_TOD_Category_index\")\n",
    "df = indexer.fit(df).transform(df)\n",
    "\n",
    "indexer = StringIndexer(inputCol=\"Start_Weekday\", outputCol=\"Start_Weekday_index\")\n",
    "df = indexer.fit(df).transform(df)\n",
    "\n",
    "# Then one-hot encode these indices\n",
    "encoder = OneHotEncoder(inputCols=[\"Start_TOD_Category_index\", \"Start_Weekday_index\"],\n",
    "                        outputCols=[\"Start_TOD_Category_vec\", \"Start_Weekday_vec\"])\n",
    "model = encoder.fit(df)\n",
    "df = model.transform(df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 7:==========>                                               (2 + 9) / 11]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+-------+\n",
      "|Traffic_Signal|  count|\n",
      "+--------------+-------+\n",
      "|             1| 165936|\n",
      "|             0|1579600|\n",
      "+--------------+-------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Calculate summary stats\n",
    "df.groupBy(\"Traffic_Signal\").count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------+--------------------+--------------------+--------------------+----+------------+--------------+-----+--------------+-------------+-----------+------------+--------------+---------------+-----------------+-------+----+--------+--------+--------+-------+-------+----------+-------+----+---------------+--------------+------------+----------+----------+-----------+-------------+------------------+--------+------------------------+-------------------+----------------------+-----------------+\n",
      "|     ID|Severity|          Start_Time|            End_Time|        Distance(mi)|Side|        City|        County|State|Temperature(F)|Wind_Chill(F)|Humidity(%)|Pressure(in)|Visibility(mi)|Wind_Speed(mph)|Precipitation(in)|Amenity|Bump|Crossing|Give_Way|Junction|No_Exit|Railway|Roundabout|Station|Stop|Traffic_Calming|Traffic_Signal|Turning_Loop|Population|Start_Year|Start_Month|Start_Weekday|Start_TOD_Category|Duration|Start_TOD_Category_index|Start_Weekday_index|Start_TOD_Category_vec|Start_Weekday_vec|\n",
      "+-------+--------+--------------------+--------------------+--------------------+----+------------+--------------+-----+--------------+-------------+-----------+------------+--------------+---------------+-----------------+-------+----+--------+--------+--------+-------+-------+----------+-------+----+---------------+--------------+------------+----------+----------+-----------+-------------+------------------+--------+------------------------+-------------------+----------------------+-----------------+\n",
      "|1607270|       2|2021-02-04T15:30:...|2021-02-04T17:31:...|               0.168|   0|  Brookhaven|      Delaware|   PA|          43.0|         43.0|       42.0|       29.89|          10.0|            3.0|              0.0|      0|   0|       0|       0|       0|      0|      0|         0|      0|   0|              0|             0|           0|      8243|      2021|          2|            5|                 4|    2.01|                     1.0|                1.0|         (5,[1],[1.0])|    (6,[1],[1.0])|\n",
      "|1607271|       2|2021-02-10T00:44:...|2021-02-10T02:10:...|               0.335|   0|    Moorpark|       Ventura|   CA|          50.0|         50.0|       80.0|       29.95|           9.0|            0.0|              0.0|      0|   0|       0|       0|       0|      0|      0|         0|      0|   0|              0|             0|           0|     36201|      2021|          2|            4|                 1|    1.43|                     5.0|                2.0|             (5,[],[])|    (6,[2],[1.0])|\n",
      "|1607272|       2|2021-02-20T16:30:...|2021-02-21T18:28:...|               0.085|   0|  Shreveport|         Caddo|   LA|          43.0|         38.0|       58.0|       30.08|          10.0|            8.0|              0.0|      0|   0|       0|       0|       0|      0|      0|         0|      0|   0|              0|             0|           0|    286200|      2021|          2|            7|                 5|   25.97|                     0.0|                5.0|         (5,[0],[1.0])|    (6,[5],[1.0])|\n",
      "|1607273|       2|2021-02-06T20:25:...|2021-02-07T23:31:...|               0.109|   1|  Shreveport|         Caddo|   LA|          46.0|         41.0|       83.0|       29.78|          10.0|           10.0|              0.0|      0|   0|       0|       0|       0|      0|      0|         0|      0|   0|              0|             0|           0|    286200|      2021|          2|            7|                 6|   27.11|                     3.0|                5.0|         (5,[3],[1.0])|    (6,[5],[1.0])|\n",
      "|1607274|       2|2021-02-11T00:41:...|2021-02-11T02:19:...|               1.129|   0|Solana Beach|     San Diego|   CA|          50.0|         50.0|       86.0|       29.68|           8.0|            0.0|              0.0|      0|   0|       0|       0|       0|      0|      0|         0|      0|   0|              0|             0|           0|     13025|      2021|          2|            5|                 1|    1.64|                     5.0|                1.0|             (5,[],[])|    (6,[1],[1.0])|\n",
      "|1607276|       2|2021-02-19T08:41:...|2021-02-19T10:39:...|               0.075|   1|  Watsontown|Northumberland|   PA|          25.0|         25.0|       92.0|       29.59|           2.0|            0.0|              0.0|      0|   0|       0|       0|       0|      0|      0|         0|      0|   0|              0|             0|           0|      1956|      2021|          2|            6|                 3|    1.97|                     2.0|                0.0|         (5,[2],[1.0])|    (6,[0],[1.0])|\n",
      "|1607278|       2|2021-01-13T17:29:...|2021-01-13T19:49:...|0.057999999999999996|   0| Chattanooga|      Hamilton|   TN|          45.0|         42.0|       53.0|        29.3|          10.0|            6.0|              0.0|      0|   0|       0|       0|       0|      0|      0|         0|      0|   0|              0|             0|           0|    403233|      2021|          1|            4|                 5|    2.34|                     0.0|                2.0|         (5,[0],[1.0])|    (6,[2],[1.0])|\n",
      "|1607279|       2|2021-01-11T18:00:...|2021-01-11T19:48:...| 0.39799999999999996|   0|  Pittsburgh|     Allegheny|   PA|          35.0|         29.0|       59.0|       28.89|          10.0|            8.0|              0.0|      0|   0|       0|       0|       0|      0|      0|         0|      0|   0|              0|             0|           0|   1720279|      2021|          1|            2|                 5|    1.81|                     0.0|                4.0|         (5,[0],[1.0])|    (6,[4],[1.0])|\n",
      "|1607280|       2|2021-02-18T06:43:...|2021-02-18T08:20:...|               0.535|   0|      Upland|San Bernardino|   CA|          54.0|         54.0|       17.0|       29.22|          10.0|           25.0|              0.0|      0|   0|       0|       0|       0|      0|      0|         0|      0|   0|              0|             0|           0|     78624|      2021|          2|            5|                 2|    1.63|                     4.0|                1.0|         (5,[4],[1.0])|    (6,[1],[1.0])|\n",
      "|1607281|       2|2021-01-12T02:24:...|2021-01-12T03:22:...|               0.525|   0|     Detroit|         Wayne|   MI|          26.0|         18.0|       85.0|       29.36|          10.0|            7.0|              0.0|      0|   0|       0|       0|       1|      0|      0|         0|      0|   0|              0|             0|           0|   3522856|      2021|          1|            3|                 1|    0.96|                     5.0|                3.0|             (5,[],[])|    (6,[3],[1.0])|\n",
      "+-------+--------+--------------------+--------------------+--------------------+----+------------+--------------+-----+--------------+-------------+-----------+------------+--------------+---------------+-----------------+-------+----+--------+--------+--------+-------+-------+----------+-------+----+---------------+--------------+------------+----------+----------+-----------+-------------+------------------+--------+------------------------+-------------------+----------------------+-----------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Severity"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Address imbalance, calculate PS, model eval, matching, calculate ATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "fraction = [0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8]\n",
    "covariates = ['Side', 'Wind_Chill(F)', 'Pressure(in)', 'Wind_Speed(mph)', 'Humidity(%)', 'Temperature(F)', \n",
    "              'Visibility(mi)', 'Amenity', 'Bump', 'Stop', 'Give_Way', 'Junction', 'No_Exit', 'Railway', \n",
    "              'Roundabout', 'Station', 'Precipitation(in)', 'Traffic_Calming', 'Crossing', 'Turning_Loop', \n",
    "              'Population', 'Start_Weekday_vec', 'Start_TOD_Category_vec']\n",
    "selected_columns = [\"Severity\", \"Traffic_Signal\"] + covariates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Fraction =  0.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC = 0.78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ATE = -0.0279\n",
      "\n",
      "\n",
      "Fraction =  0.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC = 0.781\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ATE = -0.0103\n",
      "\n",
      "\n",
      "Fraction =  0.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC = 0.78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ATE = -0.0172\n",
      "\n",
      "\n",
      "Fraction =  0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC = 0.78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ATE = 0.0017\n",
      "\n",
      "\n",
      "Fraction =  0.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC = 0.779\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ATE = 0.0112\n",
      "\n",
      "\n",
      "Fraction =  0.7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC = 0.779\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ATE = -0.0067\n",
      "\n",
      "\n",
      "Fraction =  0.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC = 0.779\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ATE = -0.0023\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "for i in fraction:\n",
    "    print(\"\\n\")\n",
    "    print(\"Fraction = \", i)\n",
    "    df_major = df.filter(F.col(\"Traffic_Signal\") == 0).sample(withReplacement=False, fraction=i, seed=1) \n",
    "    df_minor = df.filter(F.col(\"Traffic_Signal\") == 1)\n",
    "    df_balanced = df_minor.union(df_major)\n",
    "    df_ps = df_balanced.select(selected_columns)\n",
    "\n",
    "    # Define the covariates\n",
    "    assembler = VectorAssembler(inputCols=covariates, outputCol=\"features\")\n",
    "    train_data, test_data = df_ps.randomSplit([0.8, 0.2], seed=1)\n",
    "    lr = LogisticRegression(featuresCol='features', labelCol='Traffic_Signal', maxIter=10)\n",
    "    pipeline = Pipeline(stages=[assembler, lr])\n",
    "    model = pipeline.fit(train_data)\n",
    "\n",
    "    # Predict and add the propensity scores to the DataFrame\n",
    "    ps = model.transform(test_data).select('Severity', 'Traffic_Signal', 'features', 'probability')\n",
    "\n",
    "    # Extract the probability of treatment (i.e., the propensity score)\n",
    "    extract_prob = udf(lambda x: float(x[1]), FloatType())\n",
    "    ps = ps.withColumn(\"propensity_score\", extract_prob('probability'))\n",
    "\n",
    "    # Evaluate model performance on the test data\n",
    "    auc = BinaryClassificationEvaluator(labelCol='Traffic_Signal', rawPredictionCol='probability', metricName='areaUnderROC')\n",
    "    AUC = round(auc.evaluate(ps), 3)\n",
    "    print('AUC =', AUC)\n",
    "\n",
    "    ps_pd = ps.toPandas()\n",
    "\n",
    "    # Create two dataframes for treatment and control groups\n",
    "    df_treatment = ps_pd[ps_pd['Traffic_Signal'] == 1]\n",
    "    df_control = ps_pd[ps_pd['Traffic_Signal'] == 0]\n",
    "\n",
    "    # Fit nearest neighbors model to control group\n",
    "    nbrs = NearestNeighbors(n_neighbors=1).fit(df_control[['propensity_score']])\n",
    "\n",
    "    # Find nearest neighbors in control group for each treatment case\n",
    "    distances, indices = nbrs.kneighbors(df_treatment[['propensity_score']])\n",
    "\n",
    "    # Create dataframe of distances and indices\n",
    "    matches = pd.DataFrame({'distance': distances.flatten(), 'control_index': indices.flatten(),\n",
    "                            'treatment_index': df_treatment.index})\n",
    "\n",
    "    # Merge data from treatment and control cases into the matches dataframe\n",
    "    matched_pairs = matches.merge(df_treatment, left_on='treatment_index', right_index=True) \\\n",
    "        .merge(df_control, left_on='control_index', right_index=True, suffixes=('_treatment', '_control'))\n",
    "    \n",
    "    matched_pairs['Severity_treatment'] = matched_pairs['Severity_treatment'].astype(float)\n",
    "    matched_pairs['Severity_control'] = matched_pairs['Severity_control'].astype(float)\n",
    "    \n",
    "    matched_pairs['treatment_effect'] = matched_pairs['Severity_treatment'] - matched_pairs['Severity_control']\n",
    "    average_treatment_effect = matched_pairs['treatment_effect'].mean()\n",
    "    print(\"ATE =\", round(average_treatment_effect, 4))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Summary"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The average treatment effect of having a traffic signal nearby on accident severity (measured on a scale of 1 to 4, with 4 being the most severe) is -0.03 unit. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Duration"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Address imbalance, calculate PS, model eval, matching, calculate ATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "fraction = [0.05, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8]\n",
    "covariates = ['Side', 'Wind_Chill(F)', 'Pressure(in)', 'Wind_Speed(mph)', 'Humidity(%)', 'Temperature(F)', \n",
    "              'Visibility(mi)', 'Amenity', 'Bump', 'Stop', 'Give_Way', 'Junction', 'No_Exit', 'Railway', \n",
    "              'Roundabout', 'Station', 'Precipitation(in)', 'Traffic_Calming', 'Crossing', 'Turning_Loop', \n",
    "              'Population', 'Start_Weekday_vec', 'Start_TOD_Category_vec']\n",
    "selected_columns = [\"Duration\", \"Traffic_Signal\"] + covariates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Fraction =  0.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC = 0.782\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ATE = nan\n",
      "\n",
      "\n",
      "Fraction =  0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC = 0.782\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ATE = nan\n",
      "\n",
      "\n",
      "Fraction =  0.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC = 0.781\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ATE = -0.5492\n",
      "\n",
      "\n",
      "Fraction =  0.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC = 0.782\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ATE = -0.6268\n",
      "\n",
      "\n",
      "Fraction =  0.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC = 0.781\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ATE = -0.2893\n",
      "\n",
      "\n",
      "Fraction =  0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC = 0.781\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ATE = -0.3558\n",
      "\n",
      "\n",
      "Fraction =  0.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC = 0.781\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ATE = -0.2423\n",
      "\n",
      "\n",
      "Fraction =  0.7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC = 0.78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ATE = -0.3413\n",
      "\n",
      "\n",
      "Fraction =  0.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC = 0.78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ATE = -0.4505\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "for i in fraction:\n",
    "    print(\"\\n\")\n",
    "    print(\"Fraction = \", i)\n",
    "    df_major = df.filter(F.col(\"Traffic_Signal\") == 0).sample(withReplacement=False, fraction=i, seed=1) \n",
    "    df_minor = df.filter(F.col(\"Traffic_Signal\") == 1)\n",
    "    df_balanced = df_minor.union(df_major)\n",
    "    df_ps = df_balanced.select(selected_columns)\n",
    "\n",
    "    # Define the covariates\n",
    "    assembler = VectorAssembler(inputCols=covariates, outputCol=\"features\")\n",
    "    train_data, test_data = df_ps.randomSplit([0.8, 0.2], seed=1)\n",
    "    lr = LogisticRegression(featuresCol='features', labelCol='Traffic_Signal', maxIter=10)\n",
    "    pipeline = Pipeline(stages=[assembler, lr])\n",
    "    model = pipeline.fit(train_data)\n",
    "\n",
    "    # Predict and add the propensity scores to the DataFrame\n",
    "    ps = model.transform(test_data).select('Duration', 'Traffic_Signal', 'features', 'probability')\n",
    "\n",
    "    # Extract the probability of treatment (i.e., the propensity score)\n",
    "    extract_prob = udf(lambda x: float(x[1]), FloatType())\n",
    "    ps = ps.withColumn(\"propensity_score\", extract_prob('probability'))\n",
    "\n",
    "    # Evaluate model performance on the test data\n",
    "    auc = BinaryClassificationEvaluator(labelCol='Traffic_Signal', rawPredictionCol='probability', metricName='areaUnderROC')\n",
    "    AUC = round(auc.evaluate(ps), 3)\n",
    "    print('AUC =', AUC)\n",
    "\n",
    "    ps_pd = ps.toPandas()\n",
    "\n",
    "    # Create two dataframes for treatment and control groups\n",
    "    df_treatment = ps_pd[ps_pd['Traffic_Signal'] == 1]\n",
    "    df_control = ps_pd[ps_pd['Traffic_Signal'] == 0]\n",
    "\n",
    "    # Fit nearest neighbors model to control group\n",
    "    nbrs = NearestNeighbors(n_neighbors=1).fit(df_control[['propensity_score']])\n",
    "\n",
    "    # Find nearest neighbors in control group for each treatment case\n",
    "    distances, indices = nbrs.kneighbors(df_treatment[['propensity_score']])\n",
    "\n",
    "    # Create dataframe of distances and indices\n",
    "    matches = pd.DataFrame({'distance': distances.flatten(), 'control_index': indices.flatten(),\n",
    "                            'treatment_index': df_treatment.index})\n",
    "\n",
    "    # Merge data from treatment and control cases into the matches dataframe\n",
    "    matched_pairs = matches.merge(df_treatment, left_on='treatment_index', right_index=True) \\\n",
    "        .merge(df_control, left_on='control_index', right_index=True, suffixes=('_treatment', '_control'))\n",
    "    \n",
    "    matched_pairs['treatment_effect'] = matched_pairs['Duration_treatment'] - matched_pairs['Duration_control']\n",
    "    average_treatment_effect = matched_pairs['treatment_effect'].mean()\n",
    "    print(\"ATE =\", round(average_treatment_effect, 4))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Summary"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The average treatment effect of having a traffic signal nearby on accident duration (measured in hours) is -0.62 hour. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distance"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Address imbalance, calculate PS, model eval, matching, calculate ATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "fraction = [0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8]\n",
    "covariates = ['Side', 'Wind_Chill(F)', 'Pressure(in)', 'Wind_Speed(mph)', 'Humidity(%)', 'Temperature(F)', \n",
    "              'Visibility(mi)', 'Amenity', 'Bump', 'Stop', 'Give_Way', 'Junction', 'No_Exit', 'Railway', \n",
    "              'Roundabout', 'Station', 'Precipitation(in)', 'Traffic_Calming', 'Crossing', 'Turning_Loop', \n",
    "              'Population', 'Start_Weekday_vec', 'Start_TOD_Category_vec']\n",
    "selected_columns = [\"Distance(mi)\", \"Traffic_Signal\"] + covariates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Fraction =  0.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC = 0.781\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ATE = -0.3921\n",
      "\n",
      "\n",
      "Fraction =  0.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC = 0.78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ATE = -0.4592\n",
      "\n",
      "\n",
      "Fraction =  0.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC = 0.779\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ATE = -0.4461\n",
      "\n",
      "\n",
      "Fraction =  0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC = 0.778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ATE = -0.5383\n",
      "\n",
      "\n",
      "Fraction =  0.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC = 0.778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ATE = -0.5632\n",
      "\n",
      "\n",
      "Fraction =  0.7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC = 0.779\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ATE = -0.523\n",
      "\n",
      "\n",
      "Fraction =  0.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC = 0.778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ATE = -0.4762\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "for i in fraction:\n",
    "    print(\"\\n\")\n",
    "    print(\"Fraction = \", i)\n",
    "    df_major = df.filter(F.col(\"Traffic_Signal\") == 0).sample(withReplacement=False, fraction=i, seed=1) \n",
    "    df_minor = df.filter(F.col(\"Traffic_Signal\") == 1)\n",
    "    df_balanced = df_minor.union(df_major)\n",
    "    df_ps = df_balanced.select(selected_columns)\n",
    "\n",
    "    # Define the covariates\n",
    "    assembler = VectorAssembler(inputCols=covariates, outputCol=\"features\")\n",
    "    train_data, test_data = df_ps.randomSplit([0.8, 0.2], seed=1)\n",
    "    lr = LogisticRegression(featuresCol='features', labelCol='Traffic_Signal', maxIter=10)\n",
    "    pipeline = Pipeline(stages=[assembler, lr])\n",
    "    model = pipeline.fit(train_data)\n",
    "\n",
    "    # Predict and add the propensity scores to the DataFrame\n",
    "    ps = model.transform(test_data).select('Distance(mi)', 'Traffic_Signal', 'features', 'probability')\n",
    "\n",
    "    # Extract the probability of treatment (i.e., the propensity score)\n",
    "    extract_prob = udf(lambda x: float(x[1]), FloatType())\n",
    "    ps = ps.withColumn(\"propensity_score\", extract_prob('probability'))\n",
    "\n",
    "    # Evaluate model performance on the test data\n",
    "    auc = BinaryClassificationEvaluator(labelCol='Traffic_Signal', rawPredictionCol='probability', metricName='areaUnderROC')\n",
    "    AUC = round(auc.evaluate(ps), 3)\n",
    "    print('AUC =', AUC)\n",
    "\n",
    "    ps_pd = ps.toPandas()\n",
    "\n",
    "    # Create two dataframes for treatment and control groups\n",
    "    df_treatment = ps_pd[ps_pd['Traffic_Signal'] == 1]\n",
    "    df_control = ps_pd[ps_pd['Traffic_Signal'] == 0]\n",
    "\n",
    "    # Fit nearest neighbors model to control group\n",
    "    nbrs = NearestNeighbors(n_neighbors=1).fit(df_control[['propensity_score']])\n",
    "\n",
    "    # Find nearest neighbors in control group for each treatment case\n",
    "    distances, indices = nbrs.kneighbors(df_treatment[['propensity_score']])\n",
    "\n",
    "    # Create dataframe of distances and indices\n",
    "    matches = pd.DataFrame({'distance': distances.flatten(), 'control_index': indices.flatten(),\n",
    "                            'treatment_index': df_treatment.index})\n",
    "\n",
    "    # Merge data from treatment and control cases into the matches dataframe\n",
    "    matched_pairs = matches.merge(df_treatment, left_on='treatment_index', right_index=True) \\\n",
    "        .merge(df_control, left_on='control_index', right_index=True, suffixes=('_treatment', '_control'))\n",
    "    \n",
    "    matched_pairs['treatment_effect'] = matched_pairs['Distance(mi)_treatment'] - matched_pairs['Distance(mi)_control']\n",
    "    average_treatment_effect = matched_pairs['treatment_effect'].mean()\n",
    "    print(\"ATE =\", round(average_treatment_effect, 4))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Summary"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The average treatment effect of having a traffic crossing nearby on accident distance impacted (measured in miles) is -0.56 miles. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
